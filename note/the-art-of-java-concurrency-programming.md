---
layout: page
title: 《Java 并发编程的艺术》笔记
---

> **在不改变程序执行结果的前提下，尽可能提高并行度**

## 并发编程的挑战

3 个挑战：上下文切换带来的性能损耗、死锁问题、资源限制带来的挑战

### 上下文切换

什么是上下文：上下文就是线程运行的一个状态。上下文切换就是处理器在切换线程的时候不断的写入读取线程的状态。

- 第一节主要论证了一件事情：就是多线程并不一定就比单线程性能更好。原因是多线程会带来更大的上下文切换的开销。
- 怎么减少上下文切换：
    + 无锁并发编程：将 task 根据某种规则直接分配给对应的线程
    + CAS 算法：通过 CAS 算法来避免加锁。但我一直认为 CAS 算法本身就是一种乐观锁
    + 使用最少线程：上下文切换之所以会成为问题，是因为没有 task 的线程引起的上下文切换是无效的。那我们就应该尽量避免穿件多余的线程
    + 协程：在单线程里面实现多任务的调度。问题：协程之于线程，类似于线程之于进程。那为什么协程不会引起上下文切换的问题？

### 死锁

- 使用 jstack 发现死锁
- 锁的释放要放在 finally 语句块中，或者干脆使用 synchronized
- 避免死锁：
    + 避免一个线程同时获取多个锁
    + 避免一个线程在锁内占用多个资源，尽量保证每个锁只占用一个资源
    + 尝试使用定时锁，尝试使用 `lock.tryLock(timeout)` 替代内部锁机制
    + 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况

### 资源限制的挑战

大意：资源的限制使得并行程序不能完全发挥实力，甚至退化为性能更差的串行执行。需要根据资源瓶颈对症下药。

---

## Java 并发机制的底层实现

3 个主要机制的底层实现：volatile、synchronized 和原子操作

### volatile

- volatile 修饰的共享变量会在写操作时，在汇编代码前面多出一个 **lock** 前缀
    + 将 cpu 缓存行的数据写回系统内存
    + 使其他 cpu 缓存的该数据失效
- volatile 的优化，了解一下就好。主要操作是填充缓冲行

### synchronized 的原理与应用

synchronized 可以用于给普通方法（锁实例），静态方法（锁 Class 对象）和方法块（锁括号里的对象）上锁。基于 Monitor 对象的操作实现锁，书中有些地方也称之为监视器锁。

- Java 对象头：Java 对象头里面存有锁相关的信息。主要关注一个指针和锁标识位
- 锁的升级：synchronized 的锁最开始都是非常重量级的锁。为了改善性能，引入了**偏向锁**和**轻量级锁**。所以锁就有了四种状态，从低到高分别是：无锁，偏向锁，轻量级锁，重量级锁

#### 偏向锁

偏向锁的出现源于一个研究结果：大多数情况下，锁不仅不存在竞争，且总是由同一个线程多次获得

- 通过替换 Java 对象头里面的线程 ID 来获得偏向锁
- 除非出现竞争，否则不会释放偏向锁。偏向锁释放后，可能恢复到无锁状态，也可能偏向另一个线程，或者膨胀为轻量级锁。评判标准书中没有提及
- 具体的获得和释放流程可以参看书中的图片

#### 轻量级锁

- 加锁
    1. 先在栈空间中创建用于存储锁记录的空间
    2. 将 Java 对象头的 Mark Word 复制到锁记录中
    3. 尝试将 Java 对象头的 Mark Word 指向锁记录的指针
    4. 第3步失败，则自旋重试
- 解锁
    1. 将锁记录中的 Mark Word 复制回 Java 对象头
    2. 第1步失败，锁膨胀
- 具体的获得和释放流程可以参看书中的图片

#### 重量级锁

书中没有提到重量级锁的加锁和解锁。个人理解是可以参看轻量级锁的。唯一不通是重量级锁尝试获取锁失败后不会自旋重试，而是阻塞等待唤醒。

#### 优缺点对比

锁 | 优点 | 缺点 | 适用场景
-|-|-|-
偏向锁|加锁解锁不需要额外的消耗，和执行非同步方法相比仅存在纳秒极的差距|如果线程间存在锁竞争，会带来额外的锁撤销的消耗|适用于只有一个线程访问同步块场景
轻量级锁|竞争的线程不会阻塞，提高了程序的相应速度|如果始终得不到锁竞争的线程，使用自旋会消耗 cpu|追求响应时间，同步块执行速度非常快
重量级锁|线程竞争不使用自旋，不会消耗 cpu|线程阻塞，相应时间缓慢|追求吞吐量，同步块执行时间较长

个人认为这一块看一看，了解一下就好了。尤其适用场景，底层用什么锁完全是 JVM 决定的，我们程序员没法干涉

### 原子操作的实现原理

这一章降了两个层次上面原子操作的实现原理：处理器和 Java 语言

#### 处理器实现原子操作

1. 通过总线锁保证原子性。处理器向总线发出 **LOCK #** 信号，阻塞其他处理器的请求，从而独占共享内存
2. 通过缓存锁定来保证原子性。简而言之：处理器具有缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据

#### Java 如何实现原子操作

通过**锁**和**循环 CAS** 的方式来实现原子操作

1. CAS 实现原子操作的示例代码
2. CAS 原子操作的问题
    1. ABA 问题。如果数据被修改后的值和记录的旧值一样，CAS 发现不了。解决方案：加上版本号。我的问题：数据被修改过，但和旧值一样，。处理不处理有什么关系吗？直接用不就好了？
    2. CAS 自旋引起的性能问题。这个在轻量级锁里面就有提及过
    3. 只能保证一个共享变量的原子操作。解决方案：多个变量组合成为一个
3. 使用锁机制实现原子操作。比较好理解，可以类比数据库事务

---

## Java 内存模型

这一章简单介绍了 Java 的内存模型，重排序和先行发生原则。以及 volatile, lock, final 的重排序和先行发生的规则

### Java 内存模型的基础

- 线程间通信的方式：共享内存和消息传递。Java 是采用了共享内存的方式。可能在上层的代码能看到一些“消息传递”，但事实上的底层实现仍然是共享内存。
- Java 内存的抽象结构，主要分为三个部分：主内存（线程共享），本地内存（线程独有），线程（这个我理解其实就是 CPU 了）。具体可以参考书上的图理解
- 为了提高性能，指令会被重排序，主要分为三种重排序：编译器、指令并行重排、内存系统重排
- 第4小节主要介绍了不同处理器的重排序规则和内存屏障的类型。个人认为这一块太晦涩了，不是很感冒
- 先行发生原则的简介：
    + 首先，要明确一点：现行发生原则对程序员来说它是保证了可见性，并不保证他一定就是顺序执行的
    + 程序顺序规则：一个线程中的每个操作，先行发生于该线程中的任意后续操作
    + 监视器锁规则：对一个锁的解锁，先行发生于随后对这个锁的加锁。其实这就说明了监视器所是不可重入的
    + volatile 变量规则：对一个 volatile 域的写，先行发生于任意后续对这个 volatile 域的读
    + 传递性：A 先行发生于 B，B 先行发生于 C，则 A 先行发生于 C

### 重排序

#### 数据依赖性

- 什么是数据依赖性：访问同一个变量的两个操作中，存在一个写操作，那就称这两个操作存在数据依赖性
- 为什么要提到数据依赖性？数据依赖性与重排序有什么关系？只要存在数据写，那么就不能进行重排序

#### as-if-serial

直译就是看上去像线性执行。在单线程的情况下重排序会让程序运行看上去像是线性执行的，但是实际上还是有指令重排来改善性能。实现这一点的主要依据就是数据依赖性

#### 程序顺序规则

一言以蔽之，程序员可以根据先行发生原则去判断多线程下的可见性。同时 JMM 还是允许底层的实现使用重排序提高性能。
> 在不改变程序执行结果的前提下，尽可能提高并行度。

#### 重排序对多线程的影响

重排序是会对多线程产生影响的，具体可以参考书上的示例代码进行分析。

### 顺序一致性

#### 数据竞争

- 什么是数据竞争：在一个线程中写一个变量，在另一个线程中读这个变量，而且这两个操作没有通过同步排序
- 对于正确进行了同步的程序，是没有数据竞争的

#### 顺序一致性模型

这是一个理论模型，是处理器和编程语言在设计内存模型的一个参考  
顺序一致性模型的两大特性：
- 一个线程中的所有操作必须按照程序的顺序来执行
- （不管程序是否同步）所有线程都智能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须院子执行且立刻对所有线程可见

这两个特性就把并发中的三个问题：原子性，有序性，可见性全都给带上了，不愧是理论上的模型  
可以参看书上的示例来理解同步状态和非同步状态下面的顺序一致性模型的执行效果

#### 同步程序的顺序一致性效果

参看书上示例理解

#### 未同步程序的执行特性

一句话：特性就是无序，结果将变得不可预测